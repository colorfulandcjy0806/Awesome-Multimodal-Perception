# Awesome-Multimodal-Perception ğŸŒˆ

å¦‚æœä½ å¸Œæœ›é˜…è¯»æœ¬æ–‡æ¡£çš„ä¸­æ–‡ç‰ˆæœ¬ï¼Œè¯·ç‚¹å‡»[è¿™é‡Œ](./Readme.md)ã€‚ 

If you would like to read the English version of this document, please click [Here](./English.md).

Welcome to the `Awesome-Multimodal-Perception` repository, a collection of influential and inspiring papers I've encountered in my study and research in the field of multimodal perception. Multimodal perception technology is key to achieving the perceptual capabilities of artificial intelligence systems, covering a wide range of technologies from image and video analysis to speech and text understanding. Research in this field helps to advance developments in machine learning, human-computer interaction, natural language processing, and more.

In this repository, you will find a list of papers that I consider to be the most impactful and enlightening, categorized by type, along with links to the papers and their code, as well as some insightful interpretations, hoping to aid in your learning and research endeavors.

## ğŸ“– Papers List

| No.  | Type            | Paper Title                                                  | Authors                                                      | Publishing Institution           | Journal/Conference  | Paper Link                            | Code Link                                          | My Interpretation                           |
| ---- | --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------------------------------- | ------------------- | ------------------------------------- | -------------------------------------------------- | ------------------------------------------- |
| 1    | Paintingèåˆ    | VirtualPainting: Addressing Sparsity with Virtual Points and Distance-Aware Data Augmentation for 3D Object Detection | Sudip Dhakal,Dominic Carrillo,Deyuan Qu,Michael Nutt,Qing Yang,Song Fu | University of North Texas Denton | æ—                   | [ğŸ“„](https://arxiv.org/abs/2312.16141) | [ğŸ’»](https://arxiv.org/abs/2312.16141)              | [ğŸ”](https://zhuanlan.zhihu.com/p/685337158) |
| 2    | Transformeræ¶æ„ | Swin Transformer: Hierarchical Vision Transformer using Shifted Windows | Ze Liu,Yutong Lin,Yue Cao,Han Hu,Yixuan Wei,Zheng Zhang,Stephen Lin,Baining Guo | Microsoft Research Asia          | ICCV2021 Best paper | [ğŸ“„](https://arxiv.org/abs/2103.14030) | [ğŸ’»](https://github.com/microsoft/Swin-Transformer) | [ğŸ”](https://zhuanlan.zhihu.com/p/685551585) |
| ...  | ...             | ...                                                          | ...                                                          | ...                              | ...                 | ...                                   | ...                                                | ...                                         |

## ğŸ¤ How to Contribute

This project welcomes any form of contribution, whether it's adding new papers, providing interpretations, adding code links, or improving the structure of the repository. If you have any ideas or resources you'd like to share, please submit them through issues or pull requests.

## ğŸŒŸ Acknowledgements

Thank you to all the researchers and developers who have contributed to the field of multimodal perception. Your work has greatly advanced this field and provided us with a wealth of learning resources.

---

I hope this repository becomes a valuable resource on your journey of learning and researching multimodal perception. If you find the content here helpful, don't hesitate to star the repo! ğŸŒŸ
